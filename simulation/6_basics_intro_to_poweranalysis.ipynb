{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhgY7rPRd4b/hwyN93KBgd"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Experimentation Basics: Introduction to Power Analysis"
      ],
      "metadata": {
        "id": "ycaqViIls4DP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*note: if you see any mistakes, please feel free to let me know so that I can improve the notebook!*\n",
        "\n",
        "In this notebook, we will first talk about what the Power is in an experiment. Then, we will discuss what power analysis is as well as some examples and the math behind sample size calculation."
      ],
      "metadata": {
        "id": "269iavBRtOlU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Power of a Test"
      ],
      "metadata": {
        "id": "wCixK06Uy4fk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The power of a hypothesis test is the probability that the test correctly rejects the null hypothesis ($H_0$) when the alternative ($H_1$) is true.\n",
        "\n",
        "$$\\text{power}=\\Pr(\\text{reject }H_0|H_1\\text{ is true})$$\n",
        "\n",
        "In a binary hypothesis test, there are 4 different scenarios:\n",
        "1. The null is true but you incorrectly reject the null: false positive (i.e., *falsely* thinking the test is *positive*), also known as Type I error ($\\alpha$)\n",
        "2. The null is false but you incorrectly do not reject the null: false negative, also known as Type II error ($\\beta$)\n",
        "3. The null is true and you correctly do not reject the null: true negative ($1-\\alpha$)\n",
        "4. The null is false and you correctly reject the null: true positive ($1-\\beta$)\n",
        "\n",
        "This can also be represented concisely in a table below:\n",
        "\n",
        "| | The null ($H_0$) is true   | The null ($H_0$) is false |\n",
        "|-|--|-|\n",
        "|Test rejects $H_0$|$\\alpha$|$1-\\beta$|\n",
        "|Test doesn't reject $H_0$|$1-\\alpha$|$\\beta$|\n",
        "\n",
        "Intuitively speaking, you would want your A/B test to have low type I error ($\\alpha$) as well as a low type II error ($\\beta$). However, generally speaking lowering one tends to have the effect of making the other higher, creating a trade-off problem. In an extreme example, if we rejected the null no matter what, then this means that you will never be in a situation where the null is false and you don't reject the null, since you've decided to always reject the null, meaning that $\\beta=0$, your Type II error (false negative) rate is 0. However, this also means that when the null is true, you will still always reject the null therefore $\\alpha=1$ (your type I error / false positive rate is 1).\n",
        "\n",
        "In binary classification, the power of a test is also called the *sensitivity*."
      ],
      "metadata": {
        "id": "BLFZMhGBy6y1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Power Analysis"
      ],
      "metadata": {
        "id": "JQzEgI4Hy61U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Power analysis is a concept utilized extensively in A/B tests. It is used to calculate the minimum sample size required to be able to reasonably detect an effect of a given size. For example, if we would only ship a feature if it moved your primary metric by 1%, you would want to know how many samples it would take to be able to detect a 1% lift if there actually is a lift.\n",
        "\n",
        "There are lots of online tools such as [this one](https://www.evanmiller.org/ab-testing/sample-size.html).\n",
        "\n",
        "The concept of power can be also used to make comparisons between different test procedures (such as deciding between a parametric vs nonparametric test for the same hypothesis).\n",
        "\n",
        "While you can utilize the link above, a common rule of thumb is that the sample size $n$ (each group) for a two-sided two-sample $t$-test with power 80% ($\\beta=0.2$) and $\\alpha=0.05$ (the 0.80/0.05 is the typical standard) should be:\n",
        "\n",
        "$$n=16\\frac{s^2}{d^2}$$\n",
        "\n",
        "where $s^2$ is an estimate of the population variance and $d=\\mu_1-\\mu_2$ the to-be-detected difference in the mean values of both samples. For a one-sample test, replace the 16 with 8.\n",
        "\n",
        "The power will depend on 3 major factors:\n",
        "1. the statistical significance criterion ($\\alpha$) used for the test: by being less conservative and increasing $\\alpha$, your power will generally increase. However, this raises the risk of a type I error and without substantive justification, analysts typically stick with $\\alpha=0.05$.\n",
        "2. The magnitude of the effect you are interested in: to detect a smaller increase, you'll need higher samples. See how in the rule of thumb, a decrease of $d^2$ will increase $n$.\n",
        "3. Sample size: more samples will boost the power of a tset as well as everything else. More data is usually better in a hypothesis test.\n",
        "\n",
        "There are also other rules such as that it is better for control and treatment to have similar sample sizes for better power instead of uneven grouping.\n",
        "\n",
        "Next, we'll go through the math that results in the rule-of-thumb above."
      ],
      "metadata": {
        "id": "ke64U-QPy63o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sample Size Calculation"
      ],
      "metadata": {
        "id": "w2WOf7UBwpwU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When scouring the internet for the math on how sample size is calculated, it can be a little bit difficult as all the top sites seem to present a formula but rarely articulate on the derivation.\n",
        "\n",
        "Generally speaking, the procedure is to take the formula for calculating Power and do some algebra to isolate $n$ so that you calculate the sample size given various variables.\n",
        "\n",
        "We'll follow this handy [link](https://www.youtube.com/watch?v=JEAsoUrX6KQ).\n",
        "\n",
        "The video starts with assuming that you are performing two-sample $t$-test, which is one of the more common tests you will utilize in an A/B test setting.\n",
        "\n",
        "$$H_0:\\mu_c=\\mu_t$$\n",
        "$$H_1:\\mu_c\\neq\\mu_t$$\n",
        "\n",
        "The null and alternative hypothesis looks pretty typical. $\\mu_c$ represents the mean of the $c$ontrol and $\\mu_t$ is the $t$reatment.\n",
        "\n",
        "To justify the formulation of the test statistic, the video claims that under the Central Limit Theorem (e.g., sufficiently high sample sizes, which is not unreasonable for an A/B test), we have:\n",
        "\n",
        "$$\\bar x_c-\\bar x_t\\sim\\mathcal{N}\\left(\\mu_c-\\mu_t,\\frac{2\\sigma^2}{n}\\right)$$\n",
        "\n",
        "While the mean may seem familiar from previous notebooks, you may wonder how the variance is derived. My assumption is that it abuses the following 2 properties:\n",
        "1. $s$, the estimate of the standard deviation converges to $\\sigma$\n",
        "2. as per assumption of the classical $t$-test, variance and sample size is equal between both groups.\n",
        "\n",
        "Then, the [sampling distribution](https://en.wikipedia.org/wiki/Sampling_distribution) of the difference between two sample means of of two independent normal distributions has their variance / standard deviation combined to be $\\frac{2\\sigma^2}{n}$ instead of $\\frac{2\\sigma_1^2}{n_1}+\\frac{2\\sigma_2^2}{n_2}$.\n",
        "\n",
        "Then we get the test statistic,\n",
        "\n",
        "$$Z=\\frac{(\\bar x_c-\\bar x_t)-(\\mu_c-\\mu_t)}{\\sqrt{2\\sigma^2/n}}\\sim\\mathcal{N}(0,1)$$\n",
        "\n",
        "Before the next part, remember that $\\beta$ represents the type II error, the probability of falsely not rejecting the null. In other words,\n",
        "\n",
        "$$P(\\text{Accept }H_0|H_1\\text{ is true})$$\n",
        "\n",
        "Also, we know that we would reject the null if $|Z| > z_{1-\\alpha/2}$, where $Z$ is a test statistic with assuming the null (so that $\\mu_c-\\mu_t=0$). Given $\\alpha=0.05$, we know from the previous notebook that this would equal to around $1.96$.\n",
        "\n",
        "So in this case,\n",
        "\n",
        "$$Z=\\frac{(\\bar x_c-\\bar x_t)}{\\sqrt{2\\sigma^2/n}}\\sim\\mathcal{N}(0,1)$$\n",
        "\n",
        "Thus, the type 2 error is:\n",
        "\n",
        "$$P(|Z|< z_{1-\\alpha/2}|\\mu_c-\\mu_t\\neq 0)$$\n",
        "\n",
        "To calculate this, we can utilize $Z$ from earlier but we have to add in the $\\mu_c-\\mu_t$ term because we are no longer assuming the null. We also want to remove the absolute value.\n",
        "\n",
        "$$=P\\left(-z_{1-\\alpha/2}-\\frac{\\mu_c-\\mu_t}{\\sqrt{2\\sigma^2/n}}\\leq\\frac{(\\bar x_c-\\bar x_t)-(\\mu_c-\\mu_t)}{\\sqrt{2\\sigma^2/n}}\\leq z_{1-\\alpha/2}-\\frac{\\mu_c-\\mu_t}{\\sqrt{2\\sigma^2/n}}\\right)$$\n",
        "\n",
        "Even without assumping the null, the middle $Z$ still follows a standard normal distribution. Thus,\n",
        "\n",
        "$$=\\Phi\\left(z_{1-\\alpha/2}-\\frac{\\mu_c-\\mu_t}{\\sqrt{2\\sigma^2/n}}\\right)-\\Phi\\left(-z_{1-\\alpha/2}-\\frac{\\mu_c-\\mu_t}{\\sqrt{2\\sigma^2/n}}\\right)$$\n",
        "\n",
        "Since the result is similar regardless of whether or not $\\mu_t$ is greater than $\\mu_c$ or less than, we focus on just one of them, arbitrarily assume $\\mu_c> \\mu_t$.\n",
        "\n",
        "The video then focuses on the $\\Phi(\\cdot)$ to the right. It claims that it can be assumed to be close to $0$. This is likely because we know that $\\Phi(-z_{1-\\alpha/2}\\approx 1.96)$ is $0.025$ (because $\\alpha/2$), and that $-\\frac{\\mu_c-\\mu_t}{\\sqrt{2\\sigma^2/n}}$ will only make the value $0.025$ smaller, which is true since we are assuming $\\mu_c > \\mu_t$.\n",
        "\n",
        "\n",
        "In addition, the video introduces the property that $1-\\beta=\\Phi(-z_{1-\\beta})$. In addition, under the alternative hypothesis, $1-\\beta$ is the power.\n",
        "\n",
        "Thus, for the power we are left with\n",
        "\n",
        "$$\\Phi(-z_{1-\\beta})=\\Phi\\left(z_{1-\\alpha/2}-\\frac{\\mu_c-\\mu_t}{\\sqrt{2\\sigma^2/n}}\\right)$$\n",
        "\n",
        "By Taking the $\\Phi^{-1}(\\cdot)$, we are left with\n",
        "\n",
        "$$-z_{1-\\beta}=z_{1-\\alpha/2}-\\frac{\\mu_c-\\mu_t}{\\sqrt{2\\sigma^2/n}}$$\n",
        "\n",
        "Then,\n",
        "\n",
        "$$\\frac{\\mu_c-\\mu_t}{\\sqrt{2\\sigma^2/n}}=z_{1-\\alpha/2}+z_{1-\\beta}$$\n",
        "\n",
        "$$\\left(\\frac{\\mu_c-\\mu_t}{z_{1-\\alpha/2}+z_{1-\\beta}}\\right)^2=\\frac{2\\sigma^2}{n}$$\n",
        "\n",
        "$$n=\\frac{2\\sigma^2(z_{1-\\alpha/2}+z_{1-\\beta})^2}{(\\mu_c-\\mu_t)^2}$$\n",
        "\n",
        "Assuming we want $\\alpha=0.05$ and power of $1-\\beta = 0.80$, this means that\n",
        "\n",
        "$(z_{1-0.05/2}+z_{1-0.02})^2\\approx (1.96+0.842)^2\\approx 8$\n",
        "\n",
        "Then, it is easy to see that\n",
        "\n",
        "$$n\\approx 16\\frac{s^2}{d^2}$$\n",
        "\n",
        "where $s$ is the standard deviation estimate (converges to $\\sigma$ as sample size grows) and $d$ is the difference we expect from our means, $\\mu_c-\\mu_t$.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "BCdv_Kd5dgnT"
      }
    }
  ]
}