{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNQpn2gxqQs6GFwcXD4aC4s"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Topic 08 : Confidence Intervals and p-values\n",
        "\n",
        "A 95% confidence interval is a random interval that contains the parameter being estimated 95% of the time. In other words, out of all intervals computed at the 95% level, 95% of them should contain the parameter's true value.\n",
        "\n",
        "While we briefly discussed confidence intervals and p-values before in \"Basics 04\", I want to revisit this topic again and quickly make clear of the following:\n",
        "\n",
        "1. How to construct a two-sided confidence interval for an A/B Test\n",
        "2. How to use the confidence interval with the p-value"
      ],
      "metadata": {
        "id": "OsOWwk3vAcrd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Constructing a Confidence Interval\n",
        "\n",
        "We can use a two-sample Welch's $t$-test to construct the Confidence Interval. As mentioned everywhere ([Deng and Shi, 2016](https://www.kdd.org/kdd2016/papers/files/adf0853-dengA.pdf) as an example), from a practical perspective, Data Scientists often think of the z-test and t-test as the same because in many cases, the sample size is large enough that $t$-statistic is normally distributed.\n",
        "\n",
        "The $(1-\\alpha)\\cdot 100\\%$ confidence interval is ([Source](https://online.stat.psu.edu/stat415/lesson/3/3.2)):\n",
        "\n",
        "$$\\bar X_t-\\bar X_c\\pm t_{\\alpha/2,r}\\sqrt{\\frac{s_t^2}{n_t}+\\frac{s_c^2}{n_c}}$$\n",
        "\n",
        "the degrees of freedom $r$ can be approximated by:\n",
        "\n",
        "$$r=\\frac{\\left(\\frac{s_t^2}{n_t}+\\frac{s_c^2}{n_c}\\right)^2}{\\frac{(s_t^2/n)^2}{n_t-1}+\\frac{(s_c^2/n_c)^2}{n_c-1}}$$\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Let's test this out.\n",
        "\n",
        "We will first construct a data generator that generates data from a normal distribution for both control and treatment.\n",
        "\n",
        "We will then create a function that performs a statistical test and outputs the confidence interval.\n",
        "\n",
        "Then, we will run the test a bunch of times to see what % of the time the confidence interval contains the true difference in means."
      ],
      "metadata": {
        "id": "t_M67P0fActu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.stats as stats\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def data_generator_normal(n, mu1, mu2, sigma1, sigma2):\n",
        "  control = np.random.normal(mu1, sigma1, n)\n",
        "  treatment = np.random.normal(mu2, sigma2, n)\n",
        "  return control, treatment\n",
        "\n",
        "def confidence_interval(control, treatment, alpha=0.05):\n",
        "  \"\"\"\n",
        "  Calculates the confidence itnerval for the difference between two independent samples\n",
        "\n",
        "  Args:\n",
        "  - control: A numpy array containing the data for the first sample\n",
        "  - treatment: A numpy array containing the data for the second sample\n",
        "\n",
        "  Returns:\n",
        "  - A tuple containing the lower and upper bounds of the confidence interval\n",
        "  \"\"\"\n",
        "  mean_c, mean_t = np.mean(control), np.mean(treatment)\n",
        "  var_c, var_t = np.var(control, ddof=1), np.var(treatment, ddof=1)\n",
        "  n_c, n_t = len(control), len(treatment)\n",
        "\n",
        "  # calculate pooled variance\n",
        "  pooled_var = var_t/n_t + var_c/n_c\n",
        "\n",
        "  # degrees of freedom\n",
        "  df = (pooled_var**2) / ((var_t/n_t)**2 / (n_t-1) + (var_c/n_c)**2 / (n_c-1))\n",
        "\n",
        "  # critical value\n",
        "  t_critical = stats.t.ppf(1-alpha/2, df)\n",
        "\n",
        "  # interval\n",
        "  lower = mean_t - mean_c - t_critical * np.sqrt(pooled_var)\n",
        "  upper = mean_t - mean_c + t_critical * np.sqrt(pooled_var)\n",
        "\n",
        "  return lower, upper\n",
        "\n",
        "def contains_parameter(lower, upper, param=0):\n",
        "  return lower <= param and upper >= param\n"
      ],
      "metadata": {
        "id": "DL2Oxw-pwXKL"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate some data"
      ],
      "metadata": {
        "id": "3hU9sw0CCetY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "control, treatment = data_generator_normal(1000, 0, 1, 1, 1)"
      ],
      "metadata": {
        "id": "Jzbp_CBA_u2l"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lower, upper = confidence_interval(control, treatment)\n",
        "print(lower, upper)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EJ9ReTSHCJJo",
        "outputId": "f128376e-d5ed-41bc-fddb-a0207200e72f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9699110972204522 1.1458566533045635\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's actually check this formula using a built-in package"
      ],
      "metadata": {
        "id": "iSaokZ2HCgup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Run a Welch's t-test\n",
        "t_statistic, p_value = ttest_ind(treatment, control, equal_var=False)\n",
        "\n",
        "# Compute the confidence interval using the package\n",
        "confidence_interval = ttest_ind(treatment, control, equal_var=False).confidence_interval()\n",
        "\n",
        "# Print the results\n",
        "print(\"Welch's t-test:\")\n",
        "print(\"t-statistic:\", t_statistic)\n",
        "print(\"p-value:\", p_value)\n",
        "print(\"Confidence interval:\", confidence_interval)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcuSeaauCJMP",
        "outputId": "6ddc22a9-f005-4819-ca9d-72597f4bc5b0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welch's t-test:\n",
            "t-statistic: 23.583118259547682\n",
            "p-value: 1.117240533353608e-108\n",
            "Confidence interval: ConfidenceInterval(low=0.9699110972204522, high=1.1458566533045635)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We got exactly the same result. Now, let's run this a bunch of times and see how often our 95% confidence intervals include the true parameter. It should be about 95%."
      ],
      "metadata": {
        "id": "fa_RCinCDI-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_of_contains_true_param = []\n",
        "\n",
        "for _ in range(1000):\n",
        "  control, treatment = data_generator_normal(10000, 0, 1, 1, 1)\n",
        "  lower, upper = confidence_interval(control, treatment)\n",
        "  if contains_parameter(lower, upper, 1):\n",
        "    list_of_contains_true_param.append(1)\n",
        "  else:\n",
        "    list_of_contains_true_param.append(0)\n",
        "\n",
        "print(round(np.mean(list_of_contains_true_param)*100,4),'% of confidence intervals included the true parameter')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2s7-FauHTAX",
        "outputId": "5339366e-9f9f-453e-a776-fd1d2f5cc9e2"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "95.0 % of confidence intervals included the true parameter\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why the Confidence Interval is Important\n",
        "\n",
        "The reason we are discussing Confidence Intervals even though we have p-values is that knowing the p-value does not provide information about the precision of the point estimate. You can have a small p-value indicating statistical significance even if the confidence interval is wide, which suggests high uncertainty in the estimate. If your goal is to understand the precision of the point estimate, you need a confidence interval."
      ],
      "metadata": {
        "id": "pwBro_hqAcv8"
      }
    }
  ]
}