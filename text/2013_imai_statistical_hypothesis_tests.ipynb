{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM9Ozo4DGAyX1AFobxK9Gu8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# (Imai, 2013) Statistical Hypothesis Tests"
      ],
      "metadata": {
        "id": "ylCAm3FH8YP_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Updates:\n",
        "- 12/3/23: wrote up to section 1.2\n",
        "- 12/5/23: 1.3\n",
        "- 12/7/23: 1.4, 1.5, 2.1, 2.2"
      ],
      "metadata": {
        "id": "mCNwW9Jm8XqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There's a great number of introductory resources online on hypothesis testing. I've found Kosuke Imai's lecture notes on Statistical Hypothesis Tests for his class at Princeton to be one of the best out there, so we will take some notes on it below.\n",
        "\n",
        "The link is [here](https://imai.fas.harvard.edu/teaching/files/tests.pdf).\n",
        "\n",
        "For a brief background, Kosuke is a Professor (currently at Harvard) whose research focuses heavily involve causal inference. I have reviewed several of his papers as they have been very insightful. Some of my favorites are ([Ho et al., 2007](https://gking.harvard.edu/files/matchp.pdf)) and ([Imai and Kim, 2019](https://imai.fas.harvard.edu/research/files/FEmatch.pdf)).\n",
        "\n",
        "In addition, I add a lot of my own notes to help make it easier to understand (for my future self when I forget some of this stuff again!)"
      ],
      "metadata": {
        "id": "-bSgZcWO8dm9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Introduction"
      ],
      "metadata": {
        "id": "G58mghv68dpU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Any statistical hypothesis test, no matter the complexity, is based on the logic of a *stochastic proof by contradiction*.\n",
        "\n",
        "One of the famous examples of a proof by contradiction involves proving that $\\sqrt{2}$ is an irrational number by contradiction. In a hypothesis test, it is *stochastic* because it involves uncertainty. This means that we can never conclude with certainty that a hypothesis is correct. Instead, we argue that the hypothesis is *likely* incorrect."
      ],
      "metadata": {
        "id": "VEZm8M3i8drh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Hypothesis Tests for Randomized Experiments"
      ],
      "metadata": {
        "id": "AzQgeFwN8dtU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ronald Fisher invented the idea of statistical hypothesis testing."
      ],
      "metadata": {
        "id": "xmjy9hHk-4p3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.1 Lady Tasting Tea"
      ],
      "metadata": {
        "id": "2iRKPCQT-4rx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In his book, Fisher (1935) illustrates the idea of hypothesis testing with a lady tasting tea who claimed she could tell if milk was poured first or if tea was poured first.\n",
        "\n",
        "This was tested by taking 8 cups, 4 of which the milk was poured in first and the rest where the tea was poured in first. The lady got every guess correct. How likely that this is pure luck?\n",
        "\n",
        "Fisher proposed to calculate the probability of observing the outcome that is *at least as extreme* as the outcome you actually observed under the null hypothesis as the *p-value*. Intuitively, if this probability is small, then you conclude that the null hypothesis is likely to be false.\n",
        "\n",
        "For Fisher's example, we can calculate this probability easily.\n",
        "\n",
        "Remember that there are $8!$ ways to arrange the $8$ cups, but because there are two groups where in each group we treat $4$ of them the same, we have to take out the duplicates which ends up with $\\frac{8!}{4!\\cdot 4!}$. A different way of thinking about this is how many different ways can you \"choose 4\" out of 8, which is simply ${8}\\choose{4}$. If she had gotten 6 correct, we would count the number of ways you can get 6 correct (or more extreme, which is 8). However, since she got all 8 right, that is just 1 event. Thus, the p-value is $1/70$.\n",
        "\n",
        "This procedure is referred to as *Fisher's exact test* because the test computes the *exact* p-value for testing the null hypothesis. It is also called a *permutation test* because it computes all permutations of treatment assignments.\n",
        "\n"
      ],
      "metadata": {
        "id": "z3_Mwu1P-4t_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.2 Statistical Hypothesis Testing Procedure"
      ],
      "metadata": {
        "id": "ci0Yzu1N-4yT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The procedure can be summarized in 6 sequential steps:\n",
        "1. Choose $H_0$ and also $H_1$.\n",
        "2. Choose a threshold $\\alpha$, the maximum probability of *Type I error* one is willing to tolerate. Remember that Type I error is the probability of *falsely* rejecting the null. So thinking that there is an effect when there isn't.\n",
        "3. Choose a test statistic, which is a function of the observed data\n",
        "4. Derive a distribution of the test statistic under the null hypothesis. This distribution is often called the *reference distribution*.\n",
        "5. Compute the p-value by comparing the observed value of the test statistic against its reference distribution.\n",
        "6. Reject the null hypothesis if the p-value is less than the pre-specified threshold $\\alpha$ and retain the null hypothesis otherwise.\n",
        "\n",
        "Note that in Fisher's example, the null hypothesis is:\n",
        "$$H_0:Y_i(1)-Y_i(0)=0\\text{ for all }i$$\n",
        "$$H_1:Y_i(1)-Y_i(0)\\neq 0\\text{ for at least some }i$$\n",
        "\n",
        "This null is said to be *sharp* because the hypothesis is specified for each unit, which is a strong hypothesis because it assumes zero effect for *every* unit $i$.\n",
        "\n",
        "Since the example earlier of Fisher's exact test was limited to 8 data points, we can generalize it to any number of observations.\n",
        "\n",
        "Suppose we have a completely randomized experiment with binary treatment (canvassing votes). The total sample is $n$ units and randomly selected $n_1$ units are assigned to the treatment condition and the rest is assigned to the control group.\n",
        "\n",
        "The outcome is binary (turnout) and the test statistic is written as\n",
        "$$S=\\sum_{i=1}^{n}T_iY_i$$\n",
        "\n",
        "which amounts to just the # of users who had both $T_i=1$ and $Y_i=1$, so users in treatment who voted. So essentially we are seeing if canvassing votes lead to more votes.\n",
        "\n",
        "Under the sharp null hypothesis, same as above, Fisher shows that the distribution of the statistic is the *hyper-geometric distribution*,\n",
        "$$Pr(S=s)=\\frac{{m\\choose s}{n-m\\choose n_1-s}}{{n\\choose n_1}}$$\n",
        "\n",
        "where $m=\\sum_{i=1}^{n}Y_i$.\n",
        "\n",
        "For clarity,\n",
        "- $n$: total # of users\n",
        "- $m$: total # of users who voted ($Y_i=1$)\n",
        "- $n_1$: the # of users assigned to treatment\n",
        "- $s$: # of users assigned to treatment ($T_i=1$) who got outcome ($Y_i=1$)\n",
        "\n",
        "Therefore,\n",
        "\n",
        "The distribution above can be interpreted as:\n",
        "- $m\\choose s$: # of ways to get $s$ amount of users who got treatment out of total $m$ users who had $Y_i=1$\n",
        "- $n-m\\choose n_1-s$: # of ways to get users who got treatment ($T_i=1$) *and* outcome $Y_i=0$ out of total # of users ($n-m$) who got $Y_i=0$.\n",
        "- $n\\choose n_1$: # of ways to choose $n_1$ treatment users out of total $n$ users.\n",
        "\n",
        "Remember that binomial distribution can be thought of as \"probability of $s$ successes in $n_1$ draws with replacement\". On the other hand, hyper-geometric can be thought of as, \"probability of $s$ successes in $n_1$ draws *without* replacement\".\n",
        "\n",
        "So you can think of the above formula as the probability of getting an $s$ number of users ($T_i=1,Y_i=1$) out of total $n_1$ users ($T_i=1$) without replacement.\n",
        "\n",
        "Also note that this distribution can be approximated by a $\\text{Binomial}(n_1,\\frac{m}{n})$ when $n$ is large and $n_1/n$ is small.\n",
        "\n",
        "To make it more clear, imagine if we had:\n",
        "- $n=8$: 8 total users\n",
        "- $n_1=4$: 4 users who are went to a voting station with canvassing, thus 4 users without canvassing\n",
        "- $m=4$: 4 users who voted\n",
        "\n",
        "If I got $s=4$, as in all 4 people who had canvas voted, this means that all 4 people who didn't get a canvas didn't vote, and the chance of this happening is $1/70$, which you can get by plugging in the above in $HG(n_1=4,n=8,m=4)$ using any [calculator](https://homepage.divms.uiowa.edu/~mbognar/applets/hg.html).\n",
        "\n",
        "Of-course, the larger the $n$, the more permutations, and makes it difficult to compute the exact distribution. However, we can analytically obtain the following *exact* mean and variance:\n",
        "$$E(S)=\\frac{n_1\\cdot m}{n}, \\text{Var}(S)=\\frac{mn_1(n-n_1)}{n(n-1)}\\left(1-\\frac{m}{n}\\right)$$\n",
        "\n",
        "Thus, these moments can be then used to obtain an asymptotic approximation for a large $n$ via the central limit theorem:\n",
        "$$\\frac{\\{S-E(S)\\}}{\\sqrt{\\text{Var}(S)}}\\xrightarrow{d}\\mathcal{N}(0,1)$$\n",
        "\n",
        "Now what does the above math mean? It shows a few things - first off, it demonstrates the Central Limit theorem that show that the distribution of the sum of a large # of independent, identically distributed random variables approaches a normal distribution. In addition, it exploits the fact that we have the analytical formulas for the mean and the variance to standardize the normal distribution to the standard normal distribution.\n",
        "\n",
        "In a lot of statistical packages, the exact calculation is done for small sample sizes while the simulation method is used for large samples (e.g., `fisher.test()` in R). Fisher's exact test was later generalized by McNemar (1947) and Mantel and Haenszel (1959) to matched-pair and stratified designs, respectively."
      ],
      "metadata": {
        "id": "e9t_trxB-40i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.3 Testing the Population Average Treatment Effect"
      ],
      "metadata": {
        "id": "IugmMwkR7g5h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, instead of sharp effects, we consider Neyman's framework involving the *average* treatment effect:\n",
        "$$H_0:E(Y_i(1)-Y_i(0))=0$$\n",
        "\n",
        "Some history is that Neyman and Fisher used to argue a lot regarding the hypothesis testing framework. Of-course, the common feature is that they both take advantage of experimental design without making modeling assumptions.\n",
        "\n",
        "Under Neyman's framework, we begin by considering the difference in means estimator,\n",
        "$$\\hat\\tau=\\frac{1}{n_1}\\sum_{i=1}^{n}T_iY_i-\\frac{1}{n_0}\\sum_{i=1}^{n}(1-T_i)Y_i$$\n",
        "\n",
        "where $n$ is the sample size and $n_1=\\sum_{i=1}^{n}T_i$ (Thus, $n_0=n-n_1$) is the size of treatment (control) group. We assume complete randomization of treatment assignment.\n",
        "\n",
        "Previously we showed that the asymptotic sampling distribution of this statistic is given by:\n",
        "$$\\sqrt{n}(\\hat\\tau-\\tau)\\xrightarrow{d}\\mathcal{N}\\left(0,\\frac{\\sigma_1^2}{k}+\\frac{\\sigma_0^2}{1-k}\\right)$$\n",
        "\n",
        "where $k=n_1/n$, $\\tau=E(Y_i(1)-Y_i(0))$, and $\\sigma_t^2=\\text{Var}(Y_i(t))$ for $t=0,1$.\n",
        "\n",
        "If you're curious about the $\\sqrt{n}$, visit this [CrossValidated Post](https://stats.stackexchange.com/questions/591212/what-is-the-meaning-of-squared-root-n-when-we-talk-about-asymptotic-properties).\n",
        "\n",
        "Now, using this fact, we can derive thd reference distribution by substituting $\\tau=0$. Furthermore, using a consistent estimate of $\\sigma_t^2$ and applying the Slutsky Theorem, we ahve the following approximate reference distribution,\n",
        "$$Z=\\frac{\\hat\\tau}{\\text{s.e.}}\\xrightarrow{d}\\mathcal{N}(0,1)$$\n",
        "\n",
        "where $\\text{s.e.}=\\sqrt{\\frac{\\hat\\sigma_1^2}{n_1}+\\frac{\\hat\\sigma_0^2}{n_0}}$.\n",
        "\n",
        "Thus, we can use this $z$-score as a test statistic and compute the p-value based on the asymptotic reference distribution, which is the standard normal.\n",
        "\n",
        "If the alt. hypothesis is given by $H_1:E(Y_i(1)-Y_i(0))\\neq 0$, it is called *two-sided* because it allows for the possibility that the population average treatment effect (PATE) is either negative or positive.\n",
        "\n",
        "In this case, we calculate the p-value as the probability that the z-score takes the value more extreme than the observed value in terms of its absolute magnitude (i.e., $p=2\\times\\Phi(Z\\geq|Z_{\\text{obs}}|)$ where $Z_{\\text{obs}}$ is the observed value of the test statistic $Z$ and $\\Phi(\\cdot)$ is the distribution function of the standard normal random variable.\n",
        "\n",
        "Instead, if our alt. hyp. is one-sided, $H_1:E(Y_i(1)-Y_i(0))>0$, then we do not consider a negative test statistic as an extreme value because we assume that the true PATE is always negative.\n",
        "\n",
        "Thus, we use $p=\\Phi(Z\\geq Z_{\\text{obs}})$.\n",
        "\n",
        "Note how when $Z_{\\text{obs}}$ is positive, the one-sided p-value is smaller than the two-sided p-value. Thus, given the same threshold, the one-sided test is more likely to reject the null hypothesis than the two-sided test.\n"
      ],
      "metadata": {
        "id": "57nAQkZa7g71"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.4 Inverting Statistical Hypothesis Tests"
      ],
      "metadata": {
        "id": "_sWKszfO7g-Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As one might expect, there is a clear relationship between hypothesis tests and confidence intervals.\n",
        "\n",
        "Consider the generall *null* hypothesis about PATE (population ATE),\n",
        "\n",
        "$H_0:E(Y_i(1)-Y_i(0))=\\tau_0=0$\n",
        "\n",
        "In this general case, the z-score statistic and its asymptotic reference distribution are given by:\n",
        "\n",
        "$$Z=\\frac{\\hat\\tau-\\tau_0}{\\text{s.e.}}\\xrightarrow{d}\\mathcal{N}(0,1)$$\n",
        "\n",
        "Remember from last chapter that this is based on the central limit theorem, since $\\tau$ is an average.\n",
        "\n",
        "Now, consider the $(1-\\alpha)\\times 100\\%$ (e.g., if $\\alpha=0.05$, then $95\\%$) level *two*-sided test where we reject the null hypothesis if the observed value of $Z$ is greater in the absolute magnitude than the critical value $z_{1-\\alpha/2}$, defined as $\\Phi(z_{1-\\alpha/2})=1-\\alpha/2$.\n",
        "\n",
        "For example, if $\\alpha=0.05$, then $z_{1-\\alpha/2}\\approx 1.96$.\n",
        "\n",
        "Thus, our decision rule is that we reject the null $H_0:\\tau=\\tau_0$ *if and only if* $|Z_{obs}|>z_{1-\\alpha/2}$.\n"
      ],
      "metadata": {
        "id": "Y1pkTQ4b7hAS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.5 More on Permutation Tests (also known as Exact tests)"
      ],
      "metadata": {
        "id": "rsi6-V2cOcbS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Continuous Outcome**:\n",
        "\n",
        "Fisher's original formulation assumed that the outcome is binary, but his exact test can be easily extended to other types of outcome variables.\n",
        "\n",
        "For continuous outcomes, the *Wilcoxon rank-sum statistic* (Wilcoxon, 1945) is often used.\n",
        "\n",
        "Let $R_i$ be the rank of the observed outcome variable for unit $i$ where $n$ values are ordered from smallest to largest and numbered from $1$ to $n$ (ties will be considered below).\n",
        "\n",
        "The rank sum statistic is given by\n",
        "$$S=\\sum_{i=1}^{n}T_iR_i$$\n",
        "\n",
        "where $T_i$ is 1 or 0 based on Treatment status.\n",
        "\n",
        "This statistic is closely related to the *Mann and Whitney statistic* (Mann and Whitney, 1947), defined as\n",
        "$$S-\\frac{n_1(n_1+1)}{2}$$\n",
        "\n",
        "which, unlike Wilcoxon, has in general an identical distribution when the treatment and control groups are switched. Note that the latter half of that formula is a formula for adding the first $n_1$ integers.\n",
        "\n",
        "The exact distribution of Wilcoxon rank-sum statistic can be obtained by enumerating all possible permutations of the treatment assignments as before.\n",
        "\n",
        "When a sample is too large, we can use an asymptotic approximation using:\n",
        "$$E(S)=\\frac{1}{2}n_1(n+1)$$\n",
        "$$V(S)=\\frac{1}{12}n_1n_0(n+1)$$\n",
        "\n",
        "Note that $n_1$ means # of users in treatment.\n",
        "\n",
        "During a tie, there's some modifications you have to make, including a new extended formula for the asymptotic variance.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B1jJgJaDOcdb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Power of Statistical Hypothesis Tests"
      ],
      "metadata": {
        "id": "jh3IMVomOchj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember that:\n",
        "\n",
        "**Type 1 error**: Falsely rejecting the null (i.e., the null is true but we incorrectly reject it)\n",
        "\n",
        "**Type 2 error**: Falsely *not* rejecting the null (i.e., the null is false but we fail to reject it)\n",
        "\n",
        "We explicitly control for the Type 1 error via the $\\alpha$. We pick the level of test in order to specify the degree to which we are willing to tolerate false decisions if the null hypothesis is actually correct.\n",
        "\n",
        "Unfortunately, there is an explicit trade-off between the two kinds of error.\n",
        "\n"
      ],
      "metadata": {
        "id": "C-nTrPllZ0qA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Interpretation of Statistical Hypothesis Tests"
      ],
      "metadata": {
        "id": "q1PSGs68Z0sY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The failure to reject a null should not be interpreted as evidence indicating that the null is true, because we may be not rejecting it due to Type 2 error, not because the null is actually true.\n",
        "\n",
        "Also, when a p-value is small it indicates stronger evidence *against* the null, but a larger p-value can occur either because the null is true or because the test is unable to reject the null even though the null is false.\n",
        "\n",
        "Remember that the p-value is not the probability that the null is true, because that would just be 1 or 0, a value hidden to us."
      ],
      "metadata": {
        "id": "Z1FyY0COZ0uv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Power Analysis"
      ],
      "metadata": {
        "id": "wH_l3V1_a9xS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A formal analysis of the Type 2 error is referred to as the *power analysis*.\n",
        "\n",
        "Formally, the power of hypothesis is defined as the probability that we reject the null hypothesis.\n",
        "\n",
        "If the null is false, then this equals one minus the probability of type 2 error. Thus, we wish to maximize power while keeping itse size at a pre-specified level.\n",
        "\n",
        "Power analysis is useful because it allows one to examine the necessary sample size under a variety of data generating processes.\n",
        "\n",
        "Now an example.\n",
        "\n",
        "Suppose that we have a simple random sample of size $n$. For each unit, we observe a binary variable $X_i$ (say, whether a voter supports Obama).\n",
        "\n",
        "We wish to test the null $H_0:p=0.5$ where $p=Pr(X_i=1)$ representing the population of Obama supporters.\n",
        "\n",
        "Our test statistic is the following z-score, which is asymptotically distributed as normal\n",
        "$$Z=\\frac{\\hat p-0.5}{\\sqrt{0.5\\times(1-0.5)}}=2\\hat p-1\\approx\\mathcal{N}(0,1)$$\n",
        "\n",
        "Assume $\\alpha=0.05$ two-sided test.\n",
        "\n",
        "Then, we reject the null if and only if the observed value of $Z$ is either greater than 1.96 or less than -1.96.\n",
        "\n",
        "Now consider that we would like to calculate the probability that we successfully reject the null when $p=0.6$. To do this, note that the sampling distribution of $Z$ statistic under this data generating process is,\n",
        "$$\\hat p\\approx\\mathcal{N}(p,\\frac{p(1-p)}{n})$$\n",
        "\n",
        "Thus,\n",
        "$$Z=2\\hat p-1\\approx\\mathcal{N}(2p-1,\\frac{4p(1-p)}{n})$$\n",
        "\n",
        "Then, we can calculate\n",
        "$$Pr(Z>1.96)\\approx\\Phi\\left(\\frac{2p-0.96}{\\sqrt{4p(1-p)/n}}\\right)$$\n",
        "\n",
        "Then, we can manipulate $n$ to get our desired power."
      ],
      "metadata": {
        "id": "sw6CtlwFa9zI"
      }
    }
  ]
}