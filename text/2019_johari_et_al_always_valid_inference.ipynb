{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFNl4jm904Ik9NcyZL0VLA"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# (Johari et al., 2015) Always Valid Inference: Continuous Monitoring of A/B Tests"
      ],
      "metadata": {
        "id": "S2eqBEiE4GSu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Paper](https://arxiv.org/pdf/1512.04922.pdf) link\n",
        "\n",
        "> Note that this paper requires quite a number of prerequisites (that I was initially not familiar with), which I will help to annotate as we proceed with the paper.\n",
        "\n",
        "> If you want to get a head-start, I would start with reading the Wikipedia page for $\\sigma$-algebra, which can be found [here](https://en.wikipedia.org/wiki/%CE%A3-algebra).\n",
        "\n",
        "> Alternatively, watch the following 3 videos:\n",
        "- [Measure Theoretic Probability Lesson 1](https://youtu.be/swa1VRYms3Q?si=t7fTNVOLdPnmD1PJ)\n",
        "- [Measure Theoretic Probability Lesson 2](https://youtu.be/mRnZ7MudciQ?si=J2E7m4zBWaomDmjR)\n",
        "- [Measure Theoretic Probability Lesson 3](https://youtu.be/lsHr3Y9-PCA?si=3s7J002tNQIcIQs5)\n",
        "\n",
        "> To summarize main takeaways from these 3 videos, note the following concepts:\n",
        "- Take a non-empty set, often noted as $\\Omega$, and if you take a $\\sigma$-algebra of $\\Omega$, denoted as $\\mathcal{F}$ and pair them together in a tuple, $(\\Omega,\\mathcal{F})$, this is referred to as a *measurable space*, or in other words, something in which we are able to define a measure for\n",
        "- The sets in a $\\sigma$-algebra $\\mathcal{F}$ is referred to as measurable sets.\n",
        "- If you then define a *measure*, which in probability you can think of as a function that takes in a $\\sigma$-algebra and spits out a probability (a $\\mathbb{R}$ between $[0,1]$), then you can create a triple of $(\\Omega,\\mathcal{F},\\mu)$ which is called a *probability space*.\n",
        "\n",
        "> Now for the elephant in the room - what is a $\\sigma$-algebra?\n",
        "- A $\\sigma$-algebra of a set $\\Omega$ is a *collection* of *subsets* of $\\Omega$ that fulfills 3 conditions, which are called:\n",
        "  - contains $\\Omega$\n",
        "  - closed under complement (the complement of every element is also in it. So as an example, since $\\Omega$ is in a $\\sigma$-algebra, the complement of $\\{\\emptyset\\}$ must also be in the $\\sigma$-algebra too!\n",
        "  - closed under countable unions. Meaning, if $A_1$ and $A_2$ are part of the $\\sigma$-algebra, then the union $A_1\\cup A_2$ must be in the $\\sigma$-algebra too.\n",
        "\n",
        "> apparently, this is an important concept that helps measure things, such as \"almost sure convergence\" (relevant to this paper) and of-course a whole lot of other things. Apparently, $\\sigma$-algebras are pivotal in the definition of \"conditional expectation\".\n",
        "\n",
        "> I think this concept is impossible to understand without an example so an example is, imagine a set $\\Omega=\\{A,B\\}$\n",
        "\n",
        "> A \"subset\" of $\\Omega$ could be $\\{A\\}$ or $\\{B\\}$ or $\\{A,B\\}$ or even $\\{\\emptyset\\}$. In fact, the \"largest\" collection of possible subsets from $\\Omega$ is called a \"power set\" because if there are $X$ elements in the set $\\Omega$, there are $2^X$ elements in the power set. $\\mathcal{F}=\\{\\{A\\},\\{B\\},\\{A,B\\},\\{\\emptyset\\}\\}$ is an example of a $\\sigma$-algebra as well as it being a power set. Of-course, all $\\sigma$-algebras are a subset of the power set of $\\Omega$.\n",
        "\n",
        "> To further this intuition in probability, it's beneficial to use an actual probability example, so here's an example of an $\\Omega$ that involves probability: Suppose you have a set of all possible outcomes of flipping 3 coins:\n",
        "- $\\Omega = \\{HHH,HHT,HTH,THH,HTT,THT,TTH,TTT\\}$\n",
        "\n",
        "> Note that there should be $2^3=8$ entries in $\\Omega$.\n",
        "- you can now imagine how a powerset of $\\Omega$ would be all possible collections of subsets of $\\Omega$.\n",
        "\n",
        "> Now that you are powered with the prerequisites, please do the following:\n",
        "- Read the Wikipedia page for $\\sigma$-algebra, in particular, the \"Motivation\" section and make sure to learn about \"sub $\\sigma$-algebra\". This is pivotal to learn about \"sufficient statistics\", which is an important concept in likelihood. If the \"Motivation\" section is too hard, I recommend the following resources:\n",
        "  - [Great videos (2) on Limits of Sets](https://youtu.be/PZ0UhM9IB_k?si=e7OGR5BbPzpsYZcJ)\n",
        "\n",
        "> Then, learn about \"[filtration](https://en.wikipedia.org/wiki/Filtration_(probability_theory))\", which I have linked here. If you have read the above resources, the statement of \"filtrations are families of $Ïƒ$-algebras that are ordered non-decreasingly\" should at least some-what make sense.\n",
        "\n",
        "> Then, learn about \"almost-sure convergence\". Hope this [link](https://stats.stackexchange.com/questions/2230/convergence-in-probability-vs-almost-sure-convergence) helps.\n",
        "\n",
        "> Hopefully you are now ready to tackle the below paper!\n"
      ],
      "metadata": {
        "id": "l5d1oLm74GU-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Abstract"
      ],
      "metadata": {
        "id": "0cBXt67x4GYQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define *always valid* $p$-values and confidence intervals that let users try to take advantage of data as fast as it becomes available, providing valid statistical inference whenever they make their decision."
      ],
      "metadata": {
        "id": "-sxNf_rh4QFj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Introduction"
      ],
      "metadata": {
        "id": "faheXIO74QHw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our challenge is the following: can we deliver efficient inference in a simple interface, but in an environment where users continuously monitor experiments, and where their priorities regarding run-time and detection are not known in advance?\n",
        "\n",
        "We develop a statistical approach that address this challenge, and report on an implementation in a commericial A/B testing platform.\n",
        "\n",
        "The feature has the following properties:\n",
        "1. Type I error is controlled under any data-dependent rule the user might choose to stop the experiment. Continuous monitoring does not inflate Type I error.\n",
        "2. If the user stops when our $p$-value drops below her personal $\\alpha$, the resulting rule approximately obtains an efficient rade-off for run-time and detection, even with no advance knowledge of her preferences. More specifically, we focus on users that generally want short tests and good detection, modeled as follows: the user stops at either the first time the $p$-value process crosses $\\alpha$, or at a fixed maximum *failure time* $M$, whichever comes first. A larger $M$ indicates greater patience and a corresponding preference for detection of smaller effects.\n",
        "\n",
        "Our main contribution is to demonstrate that always valid $p$-values derived from a particular class of sequential tests known as mSPRTs achieve an efficient tradeoff between power and run-time for such users to first order in $M$ as $M\\rightarrow\\infty$.\n",
        "\n",
        "The mSPRT invovles stopping the first time a mixture of the likelihood ratio of alternative to null crosses a threshold, where the mixture is over potential values of the alternative.\n"
      ],
      "metadata": {
        "id": "o3NSU0_g4QJ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Related work"
      ],
      "metadata": {
        "id": "9LZpGKKe4QL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1. Sequential hypothesis testing"
      ],
      "metadata": {
        "id": "R-0gSdkoLSCW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sequential analysis is a mature field with roots dating back to Wald (1945), and sequential tests are widely used in areas such as pharmaceutical clinical trials."
      ],
      "metadata": {
        "id": "O1_xfaavLSEo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Sequential confidence intervals and the LIL"
      ],
      "metadata": {
        "id": "AfiC8hmwLSG_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Some discussion of the Law of the Iterated Logarithm (LIL) and why mSPRT is the most appropriate choice for an A/B testing platform"
      ],
      "metadata": {
        "id": "3hFRuXNlLSJg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.3 Bandit algorithms"
      ],
      "metadata": {
        "id": "jzEM-EF0d-N-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a review of the literature on *multi-armed bandits*, check out (Lattimore and Szepesvari, 2018), and for how it is used in the industry in place of hypothesis testing, refer to (Scott 2015).\n",
        "\n",
        "Explains why the hypothesis testing framework remains the dominant form of A/B testing in industrial deployment, including reasons related tothe interest in *inference*. However, bandit methods are also practically valuable and developing methods for inference with adaptive allocation remain interesting directions for future work.\n",
        "\n"
      ],
      "metadata": {
        "id": "vUQ5MWr0d-Rk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.4 Sequential multiple hypothesis testing"
      ],
      "metadata": {
        "id": "1hTWh3O2fXtC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There has also been recent interest in achieving multiple hypothesis testing controls in sequential contexts. For the most part, work in this area considers a different form of streaming data to the one described in this paper: Refer to (Javanmard and Montanari, 2016) to learn about \"$\\alpha$-spending\" and \"$\\alpha$-investing\" methods to control the family-wise error rate (FWER) or the false disovery rate (FDR) when experiments are performed sequentially, but within each experiment the data is accessed only once.\n",
        "\n",
        "Yang et al. (2017) combines $\\alpha$-investing with sequential hypothesis testing to enable FDR control in this regime.\n",
        "\n",
        "Malek et al. (2017) investigates when always valid $p$-values can be used to achieve other multiple testing bounds beyond FWER and FDR.\n",
        "\n"
      ],
      "metadata": {
        "id": "4h95tMHrfXvL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Preliminaries"
      ],
      "metadata": {
        "id": "iUQo7i--fXxT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To begin, we suppose that our data can be modeled as independent observations from an exponential family\n",
        "\n",
        "$$\\mathbb{X}=(X_n)_{n=1}^\\infty\\overset{i.i.d}\\sim F_\\theta$$\n",
        "\n",
        ", where the parameter $\\theta$ takes values in $\\Theta\\subset\\mathbb{R}^p$.\n",
        "\n",
        "> The above can be interpreted as observations $X_n$ where it goes from $n=1$ to $\\infty$ that are all iid.\n",
        "\n",
        "Throughout the paper, $(\\mathcal{F}_n)_{n=1}^{\\infty}$ will denote the filtration generated by $(X_n)_{n=1}^{\\infty}$ and $\\mathbb{P}_\\theta$ will denote the measure (on any space) induced under the parameter $\\theta$.\n",
        "\n",
        "> Okay, what in the heck does that mean? A filtration is a sequence of $\\sigma$-algebras that represent the available information at different stages or time points. Here, $\\mathcal{F}_n$ represents the information available up to time (or step) $n$. It contains all the events that can be determined based on the values of $X_1, X_2, \\ldots, X_n$. In other words, $\\mathcal{n}$ is a $\\sigma$-algebra of a sequence of $X_n$'s up to $n$. (I think)\n",
        "\n",
        "Our focus is testing a simple null hypothesis $H_0:\\theta=\\theta_0$ against the composite alternative $H_1:\\theta\\neq\\theta_0$. (Later in Section 6 we discuss two-sample hypothesis testing which will be needed for an A/B test)\n",
        "\n",
        "**Decision rules:**\n",
        "\n",
        "In general, a decision rule is a pair $(T,\\delta)$ where $T$ is a (possibly infinite) stopping time for $(\\mathcal{F}_n)_{n=1}^\\infty$ that denotes the sample size at which the test is ended, and $\\delta$ is a binary-valued, $(\\mathcal{F}_T)$-measurable random variable, where $\\delta=1$ indicates that $H_0$ is rejected; note that $\\delta=0$ must hold almost surely if $T=\\infty$.\n",
        "\n",
        "> Here's an AI-generated explanation of this decision rule:\n",
        "Being $(\\mathcal{F}_T)$-measurable refers to a property of a random variable or an event in the context of a stochastic process, specifically in relation to a filtration $(\\mathcal{F}_n)_{n=1}^\\infty$.\n",
        "\n",
        "> Here's what it means:\n",
        "\n",
        "> Filtration: A filtration $(\\mathcal{F}n)_{n=1}^\\infty$ is a sequence of sigma-algebras that represent the available information at different stages or time points in a stochastic process. Each $\\mathcal{F}_n$ contains all the events that can be determined based on the outcomes observed up to time $n$.\n",
        "\n",
        "> $(\\mathcal{F}_T)$-Measurable: A random variable or an event is said to be $(\\mathcal{F}_T)$-measurable if it can be determined or evaluated based on the information available at the stopping time $T$. In other words, if an event or a random variable is $(\\mathcal{F}_T)$-measurable, it means that its occurrence or value can be determined at or before time $T$ using the information available up to that time.\n",
        "\n",
        "> In the context of the provided text, a decision rule is defined as a pair $(T,\\delta)$, where $T$ is a stopping time representing the sample size at which the test is ended, and $\\delta$ is a binary-valued, $(\\mathcal{F}_T)$-measurable random variable indicating whether to reject the null hypothesis $H_0$. Being $(\\mathcal{F}_T)$-measurable ensures that the decision $\\delta$ can be made based on the information available up to the stopping time $T$.\n",
        "\n",
        "> In summary, $(\\mathcal{F}_T)$-measurable means that an event or random variable can be determined or evaluated based on the information available up to the stopping time $T$ in a stochastic process.\n",
        "\n",
        "**Type I error**:\n",
        "\n",
        "Type I error is the probability of erroneous rejection under the null, i.e., $\\mathbb{P}_{\\theta_0}(\\delta=1)$\n",
        "> the probability of $\\delta$ being $1$ (reject) when $\\theta=\\theta_0$, which is the null.\n",
        "\n",
        "**Sequential tests**:\n",
        "\n",
        "Given $\\alpha$, we typically consider a family of decision rules parameterized by $\\alpha$. Formally, a *sequential test* is a family of decision rules $(T(\\alpha),\\delta(\\alpha))$ indexed by $\\alpha\\in(0,1)$ such that:\n",
        "1. The decision rules are *nested*: $T(\\alpha)$ is 'almost-surely' nonincreasing in $\\alpha$, and $\\delta(\\alpha)$ is 'almost-surely' nondecreasing in $\\alpha$.\n",
        "\n",
        "> I believe this means that almost-surely (a term relating to convergence), as $\\alpha$ decreases, $T$ increases. Similarly, as $\\alpha$ increases, $\\delta$ increases too, meaning that the probability of rejection goes up.\n",
        "\n",
        "2. For each $\\alpha$, the Type I error is bounded by $\\alpha:\\mathbb{P}_{\\theta_0}(\\delta=1)\\leq\\alpha$\n",
        "\n",
        "**Fixed Horizon Testing**:\n",
        "\n",
        "Under the default fixed horizon testing approach, we restrict the decision rules $(n,\\delta)$ where the stopping time is required to be deterministic. In this setting, the objective is to maximize the power (the probability of detection under $H_1$) at that $n$. Indeed, for data in an exponential family, for any given $n$, there exist a family of uniformly most powerful (UMP) tests parametrized by $\\alpha$, each of which maximizes power uniformly over $\\theta$ among tests with Type I error rate $\\alpha$. These tests reject the null if a particular test statistic $\\tau_n$ exceeds a threshold $k(\\alpha)$.\n",
        "\n",
        "While the tests maximize power for a given $n$, the power increases as $n$ is increased, and so the user must choose $n$ to trade off power against the opportunity cost of waiting for more samples. The challenge for the user is that the power is a steep function of the true $\\theta$, so good advance knowledge on the size of the effect sought is required.\n",
        "\n",
        "**The fixed horizon user interaction model**:\n",
        "\n",
        "Testing platforms typically allow users to implement their optimal test via $p$-values. Specifically, the $p$-value at time $n$ corresponding to the UMP test is:\n",
        "\n",
        "$$p_n=\\text{inf}\\{\\alpha:\\tau_n\\geq k(\\alpha)\\}$$\n",
        "\n",
        "In other words, this $p$-value is the smallest $\\alpha$ such that the $\\alpha$-level test with sample size $n$ rejects $H_0$.\n",
        "\n",
        "The process $p_n$ provides sufficient information for the user to implement her desired test with ease: she waits for her chosen $n$, and rejects the null if $p_n\\leq\\alpha$. In addition, $p_n$ ensures transparency in the following sense: since each rule $\\delta_n(\\alpha)$ controls Type I error at level $\\alpha$, any other user can threshold the $p$-value obtained at her own appropriate $\\tilde\\alpha$ level to satisfy her desired Type I error bound.\n",
        "\n",
        "In fact, to control Type I error, we require only that the $p$-value is *super-uniform*:\n",
        "\n",
        "$$\\forall s\\in[0,1],\\mathbb{P}_0(p_n\\leq s)\\leq s$$\n",
        "\n",
        "> This means that for any chosen significance level $s \\in [0,1]$, the probability that $p_n$ is less than or equal to $s$ under the null hypothesis $\\mathbb{P}_0(p_n \\leq s)$ should not exceed $s$.\n",
        "Super-uniformity ensures that the $p$-value maintains its validity in controlling Type I error rates across different significance levels, providing robustness and reliability in hypothesis testing. Remember that you can interpret $p_n\\leq s$ as just the probability of rejecting the null. So the probability of incorrectly rejecting the null should not exceed $s$.\n",
        "\n",
        "More generally, we refer to any $[0,1]$-valued, $(\\mathcal{F}_n)$-measurable random variable $p_n$ that satisfies the above as a *fixed horizon $p$-value* process for the choice of sample size $n$.\n",
        "\n",
        "Confidence intervals can be constructed from the tests $\\delta_n(\\alpha)$ associated with fixed horizon $p$-values for $H-0:\\theta=\\tilde\\theta$ at each $\\tilde\\theta\\in\\Theta$ by considering the set of $\\theta$ that are not rejected. What matters is the following coverage bound: a $(1-\\alpha)$-level fixed horizon confidence interval is any $(\\mathcal{F}_n)$-measurable random set $CI_n\\subset\\Theta$ where\n",
        "\n",
        "$$\\forall\\theta\\in\\Theta,\\mathbb{P}_\\theta(\\theta\\in CI_n)\\geq 1-\\alpha$$"
      ],
      "metadata": {
        "id": "KO20byDZqKp3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Always valid inference"
      ],
      "metadata": {
        "id": "7JsUf5WVd-Ue"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our goal is to let the user stop the test whenever they want, in order to trade off power with run-time as they see fit; the $p$-value they obtain should control Type I error. Our first contribution is the definition of *always valid* $p$-values as those processes that achieve this control.\n",
        "\n",
        "**DEFINITION 1**:\n",
        "\n",
        "A sequence of fixed horizon $p$-values ($p_n$) is an *always valid $p$-value* process if given any (possibly infinite) stopping time $T$ with respect to $(\\mathcal{F}_n)$, there holds:\n",
        "\n",
        "$$\\forall s\\in[0,1],\\mathbb{P}_{\\theta_0}(p_T\\leq s)\\leq s$$\n",
        "\n",
        "The following theorem demonstrates that always valid p-values are in a natural correspondence with sequential tests.\n",
        "\n",
        "**THEOREM 1**:\n",
        "\n",
        "1. Let $(T(\\alpha),\\delta(\\alpha))$ be a *sequential test*. Then, $$p_n=\\text{inf}\\{\\alpha:T(\\alpha)\\leq n,\\delta(\\alpha)=1\\}$$ defines an always valid p-value process.\n",
        "\n",
        "> In essence, $p_n$ is the smallest significance level $\\alpha$ at which the null hypothesis is rejected within the first $n$ observations, indicating the strength of evidence against the null hypothesis at time $n$.\n",
        "\n",
        "2. For any always valid p-value process $(p_n)_{n=1}^{\\infty}$, a sequential test $(\\tilde T(\\alpha),\\tilde\\delta(\\alpha))$ is obtained from $(p_n)_{n=1}^\\infty$ as follows:\n",
        "\n",
        "$$\\tilde T(\\alpha)=\\text{inf}\\{n:p_n\\leq\\alpha\\};$$\n",
        "\n",
        "$$\\tilde\\delta(\\alpha)=\\mathbb{1}\\{\\tilde T(\\alpha)\\leq\\infty\\}$$\n",
        "\n",
        "If $(p_n)_{n=1}^{\\infty}$ was derived as in $\\forall s\\in[0,1],\\mathbb{P}_0(p_n\\leq s)\\leq s$ and $T=\\infty$ whenever $\\delta=0$, then $(\\tilde T(\\alpha),\\tilde\\delta(\\alpha))=(T(\\alpha),\\delta(\\alpha))$\n",
        "\n",
        "> In summary, Definition 1 establishes criteria for \"always valid\" $p$-values, ensuring that they control Type I error rates regardless of when the test is stopped. Theorem 1 demonstrates the relationship between \"always valid\" $p$-values and sequential tests, showing how they can be derived from each other while maintaining statistical validity.\n",
        "\n",
        "the p-values from the results above are almost-surely *monotonically non-increasing* in $n$.\n",
        "\n",
        "> In other words, as $n$ goes up, $p$-value goes down?\n",
        "\n",
        "The above creates a one-to-one correspondence between monotone always valid p-value processes and families of sequential tests that do not give up for failture; i.e., where $\\delta=0$ implies $T=\\infty$.\n",
        "\n",
        "These processes can be seen as the natural representation of those sequential tests in a streaming p-value format.\n",
        "\n",
        "**Confidence intervals**:\n",
        "\n",
        "Always valid CIs are defined analogously and may be constructed from always valid p-values just as in the fixed horizon context. Proposition 1 follows immediately from the definitions.\n",
        "\n",
        "**DEFINITION 2**: A sequence of fixed horizon $(1-\\alpha)$-level confidence intervals ($CI_n$) is an *always valid $(1-\\alpha)$-level confidence interval process if, given any stopping time $T$ with respect to $(\\mathcal{F}_n)$, there holds:\n",
        "\n",
        "$$\\forall\\theta\\in\\Theta,\\mathbb{P}_\\theta(\\theta\\in CI_T)\\geq 1-\\alpha$$\n",
        "\n",
        "**PROPOSITION 1**: Suppose that, for each $\\tilde\\theta\\in\\Theta$, $(p_n^\\tilde\\theta)$ is an always valid p-value process for the test of $\\theta=\\tilde\\theta$. Then\n",
        "\n",
        "$$CI_n=\\{\\theta:p_n^\\theta>\\alpha\\}$$\n",
        "\n",
        "is an always valid $(1-\\alpha)$-level CI process.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mEpCLNkw6stE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Efficient always valid p-values via the mSPRT"
      ],
      "metadata": {
        "id": "rNYQ9FuQ6svi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Users who continuously monitor experiments are making a dynamic tradeoff between two objectives: detecting true effects with maximum probability and minimizing the typical length of experiments.\n",
        "\n",
        "A natural model for this is done using the following: Take the Type I error tolerance, $\\alpha$, and the maximum number of observations $M$ they can afford. We assume that such a user stops and rejects $H_0$ at either the first time the always valid p-value crosses $\\alpha$, or at time $M$, whichever comes first.\n",
        "\n",
        "We refer to such a user as a type $(M,\\alpha)$ user. Informally, our goal is to deliver high power at low relative run-lengths. To achieve this goal, we consider always valid p-value processes derived from a particular family of sequential tests called the *mixture sequential probability ratio tests* (mSPRT). The mSPRT stops the first time a mixture (over treatment effects) of likelihood ratios against the null crosses a threshold. First introduced by Robbins (1970).\n",
        "\n",
        "We study \"efficiency\" of an always valid p-value process via the \"power profile\" (probability that true effects are detected) and \"relative run-length profile\" (expected run-length for such a user, normalized by $M$) across possible treatment effects.\n",
        "\n",
        "For a certain kind of users ($M\\sim\\log(1/\\alpha)$), the mSPRT satisfies a desirable first-order efficiency property: there is no other feasible decision rule that yields a relative run-length that is lower on some non-null effects, while meeting the size constraint $\\alpha$ and yielding a higher power at all non-null effects.\n",
        "\n",
        "However, we should expect that our performance will be influenced by the choice of the mixing distribution. In Section 5.6.1, we see that while the choice of mixture matters, we also find that the performance of the mSPRT is surprisingly robust to misspecification.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Y6YBiuRi6szx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 The user model"
      ],
      "metadata": {
        "id": "qWDMyq4z6s2M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the remainder of this section, our goal will be to make near-optimal tradeoffs between power and run-length for users in the limit where $\\alpha\\rightarrow 0$ without prior knowledge of their preferences, $(M,\\alpha)$.\n",
        "\n",
        "Given the equivalence to a sequential test $(T(\\alpha),\\delta(\\alpha))$, we define the $(M,\\alpha)$ user's decision rule by $T(M,\\alpha)\\overset{\\Delta}=\\min\\{T(\\alpha),M\\}$ and remark that $\\delta(M,\\alpha)=1$ if and only if $T(\\alpha)\\leq M$."
      ],
      "metadata": {
        "id": "p4IvjfCXFuRd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 The mSPRT"
      ],
      "metadata": {
        "id": "zq5VxYIgFuTt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We begin by imposing slight restrictions on the data model: we assume that the data is real valued and drawn from a single parameter exponential family,\n",
        "\n",
        "$$f_\\theta(x)=F_\\theta'(x)=f_0(x)\\exp(\\theta x-\\psi(\\theta))$$\n",
        "\n",
        "where tests are of the natural parameter $\\theta$, $\\Theta$ is an open interval, $\\psi''(\\theta)>0$ for all $\\theta$, and $E|X_1|^4<\\infty$. The function $\\psi(\\theta)$ is referred to as the *log partition function* for the family.\n",
        "\n",
        "The mSPRT is parameterized by a *mixing distribution* $H$ over $\\Theta$, which we restirct to have everywhere continuous and positive derivative.\n",
        "\n",
        "> I think \"everywhere positive derivative\" implies that the distribution is monotonically increasing?\n",
        "\n",
        "Given an observed sample average $s_n$ up to time $n$, the likelihood ratio of $\\theta$ against $\\theta_0$ is $(f_\\theta(s_n)/f_{\\theta_0}(s_n))^n$. Thus we define the *mixture likelihood ratio* with respect to $H$ as\n",
        "\n",
        "$$\\Lambda_n^H(s_n)=\\int_\\Theta\\left(\\frac{f_\\theta (s_n)}{f_{\\theta_0}(s_n)}\\right)^ndH(\\theta)$$\n",
        "\n",
        "> Intuitively, if there seems to be more evidence (from the data, $s_n$) that the alternate hypothesis is likely, than the likelihood ratio will be larger. This should mean that the larger the ratio, the higher the chance of rejection. Let's see if that translates below.\n",
        "\n",
        "The mSPRT is then defined by:\n",
        "\n",
        "$$T^H(\\alpha)=\\inf\\{n:\\Lambda_n^H(S_n)\\geq\\alpha^{-1}\\}$$\n",
        "\n",
        "$$\\delta^H(\\alpha)=1_{\\{T^H(\\alpha)<\\infty\\}}$$\n",
        "\n",
        "> Let's see if the above makes sense. We're saying that the time you stop the experiment is the first time that the likelihood is greater than $\\alpha^-1$. Note that $0.05^{-1}=20$ and $0.01^{-1}=100$. Thus, the smaller the $\\alpha$, the larger our likelihood has to be to reject the null. This should be in line with our intuition that the larger the likelihood the better.\n",
        "\n",
        "$S_n=\\sum_{i=1}^nX_i/n$. The choice of the threshold $\\alpha^{-1}$ on the likelihood ratio ensure Type I error is controlled at level $\\alpha$. Intuitively, the $\\Lambda$ represents the evidence against $H_0$ in favor of a mixture of alternative hypotheses, based on the first $n$ observations. The test rejects $H_0$ if the accumulated evidence ever becomes large enough.\n",
        "\n",
        "Our first motivation for consdiering mSPRTs is that they are *tests of power one*: for all $\\alpha$ and $\\theta\\neq\\theta_0$, there holds:,\n",
        "\n",
        "$$\\mathbb{P}_\\theta(T(\\alpha)<\\infty,\\delta(\\alpha)=1)=1$$\n",
        "\n",
        "In other words, for the hypothetical user who can wait forever, any mSPRT delivers power one for any alternative."
      ],
      "metadata": {
        "id": "rPc1vXJZI7zZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.4 First-order efficiency in the $\\alpha\\rightarrow 0$ limit"
      ],
      "metadata": {
        "id": "axNZlODbI717"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now formalize our study of the power and run-length tradeoff for an $(M, Î±)$ user. In this section,\n",
        "the set of $(T(M, Î±), Î´(M, Î±))$ decision rules is referred to as the set of feasible decision rules for an\n",
        "$(M, Î±)$ user.\n",
        "\n",
        "An $(M, Î±)$ user will want to choose her decision rule to maximize the *power profile* $\\nu(\\theta)=\\mathbb{P}_\\theta(\\delta=1)$ over $\\theta\\neq\\theta_0$. Second, she will want to minimize the *relative run-length profile*, i.e., the run-length measured against the maximum available to her, $\\rho(\\theta)=\\mathbb{E}_\\theta(T)/M$, viewed as a function of $\\theta$.\n",
        "\n",
        "> Intuitively, you want a high $\\nu(\\theta)$ and a low $\\rho(\\theta)$.\n",
        "\n",
        "*Perfect efficiency* would entail $\\rho(\\theta)=0$ and $\\nu(\\theta)=1$ for all $\\theta\\neq\\theta_0$. Of-course, this is generally unnattainable for feasible decision rules. In this section we study the best achievable performance a user can hope for, in the limit where $\\alpha\\rightarrow 0$."
      ],
      "metadata": {
        "id": "j94ca-6bfm2V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.4 The role of the mixing distribution $H$"
      ],
      "metadata": {
        "id": "EVvmbzbQfm5R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The choice of $H$ does influence the tradeoff between performance at different effect sizes, and this tradeoff will yield a relevant second order effect on performance."
      ],
      "metadata": {
        "id": "yTfiXtv3kYIi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.5 Comparison to fixed-hirizon testing"
      ],
      "metadata": {
        "id": "ZkZLomUckYLF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In general, the fixed-horizon sample size must be chosen in reference to the effect sizes where detection is needed; therefore, we compare performance of the mSPRT to a fixed-horizon test that is calibrated to have good average power over the prior $G$."
      ],
      "metadata": {
        "id": "ZSwomsIEFuWD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.6 Empirical analysis"
      ],
      "metadata": {
        "id": "kZCV90eol2GC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Showed that a misspecification of the mixing distribution was not too consequential."
      ],
      "metadata": {
        "id": "cxJ-lrTTl2Iu"
      }
    }
  ]
}